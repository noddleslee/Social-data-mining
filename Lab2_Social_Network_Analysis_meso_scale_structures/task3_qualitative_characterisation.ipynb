{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d115023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8fe594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "# ---------- 1) Load accounts.tsv ----------\n",
    "accounts_path = DATA_DIR / \"accounts.tsv\"\n",
    "accounts_df = pd.read_csv(\n",
    "    accounts_path,\n",
    "    sep=\"\\t\",\n",
    "    dtype=str,\n",
    "    keep_default_na=False\n",
    ")\n",
    "accounts_df.columns = [c.strip() for c in accounts_df.columns]\n",
    "if \"author_id\" not in accounts_df.columns:\n",
    "    for alt in [\"user_id\", \"id\", \"account_id\"]:\n",
    "        if alt in accounts_df.columns:\n",
    "            accounts_df = accounts_df.rename(columns={alt: \"author_id\"})\n",
    "            break\n",
    "\n",
    "# ---------- 3) helpers to parse tweets.dat ----------\n",
    "tweets_path = DATA_DIR / \"tweets.dat\"\n",
    "\n",
    "def safe_get(d, *keys, default=None):\n",
    "    cur = d\n",
    "    for k in keys:\n",
    "        if not isinstance(cur, dict) or k not in cur:\n",
    "            return default\n",
    "        cur = cur[k]\n",
    "    return cur\n",
    "\n",
    "def parse_created_at(ts):\n",
    "    if not ts:\n",
    "        return None\n",
    "    try:\n",
    "        return datetime.fromisoformat(ts.replace(\"Z\", \"+00:00\"))\n",
    "    except Exception:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae9aa4b",
   "metadata": {},
   "source": [
    "## qualitative characterisation of Bot group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5172f2b7",
   "metadata": {},
   "source": [
    "From the bot network in Task 2, we first identified the largest connected component (51 accounts).\n",
    "Within this component, we then applied the Louvain algorithm and selected its largest community (36 accounts) as the meso-level structure to analyse.\n",
    "This community shows a high level of synchronised posting behaviour, with multiple accounts sharing the same URLs within extremely short time windows.\n",
    "Such coordination is unlikely for human-driven accounts, so this group appears to be the most suspicious and the most likely to contain automated or bot-like actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf676f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected bot community: 0\n",
      "Number of users in bot group: 36\n",
      "Example *author_id*: ['1413949782', '4304243774', '567045831', '3628769299', '363399297', '193735085', '4010844315', '1022779850', '955688402', '3426754877']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "# 1) read VertexClustering\n",
    "BOT_COMMS_PATH = DATA_DIR / \"G_bot_gc_comms.pkl\"\n",
    "with open(BOT_COMMS_PATH, \"rb\") as f:\n",
    "    bot_gc_comms = pickle.load(f)   # igraph.clustering.VertexClustering\n",
    "\n",
    "# 2) get underlying igraph.Graph\n",
    "g_bot_gc_ig = bot_gc_comms.graph\n",
    "\n",
    "# 3) select the community you want to analyze (k_bot = 0 → size=36)\n",
    "k_bot = 0\n",
    "bot_vertex_indices = bot_gc_comms[k_bot]   # this is a list of indices like [46, 7, 39, 40, ...]\n",
    "\n",
    "# 4) use vertex index to look up vs[\"name\"], get the real author_id\n",
    "bot_user_ids = {\n",
    "    str(g_bot_gc_ig.vs[idx][\"name\"])   # name is the original node (author_id)\n",
    "    for idx in bot_vertex_indices\n",
    "}\n",
    "\n",
    "print(\"Selected bot community:\", k_bot)\n",
    "print(\"Number of users in bot group:\", len(bot_user_ids))\n",
    "print(\"Example *author_id*:\", list(bot_user_ids)[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6b067",
   "metadata": {},
   "source": [
    "After identifying the largest connected component (51 nodes) in the bot network, we applied the Louvain algorithm on this component and selected its largest community (36 nodes) as our meso-level structure.\n",
    "This gave us a list of actors (author_id values) belonging to this group.\n",
    "\n",
    "The next step was to extract all tweets written by these accounts.\n",
    "To do this, we scanned the entire tweets.dat file and collected every tweet whose author_id matched one of the user IDs in the selected community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5622f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_tweets_for_users(user_ids, tweets_path, max_lines=None):\n",
    "    user_ids = set(user_ids)\n",
    "    rows = []\n",
    "\n",
    "    with open(tweets_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if max_lines is not None and i >= max_lines:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                tw = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "            aid = str(tw.get(\"author_id\", \"\")).strip()\n",
    "            if aid not in user_ids:\n",
    "                continue\n",
    "\n",
    "            # basic fields\n",
    "            created_at = tw.get(\"created_at\")\n",
    "            lang = tw.get(\"lang\")\n",
    "            text = tw.get(\"text\", \"\")\n",
    "\n",
    "            # URLs (may be empty)\n",
    "            urls = safe_get(tw, \"entities\", \"urls\", default=[])\n",
    "            expanded_urls = []\n",
    "            domains = []\n",
    "            if isinstance(urls, list):\n",
    "                for u in urls:\n",
    "                    uu = u.get(\"expanded_url\") or u.get(\"url\")\n",
    "                    if uu:\n",
    "                        expanded_urls.append(uu)\n",
    "                        try:\n",
    "                            domains.append(urlparse(uu).netloc)\n",
    "                        except Exception:\n",
    "                            domains.append(None)\n",
    "\n",
    "            rows.append({\n",
    "                \"tweet_id\": str(tw.get(\"id\", \"\")),\n",
    "                \"author_id\": aid,\n",
    "                \"created_at\": created_at,\n",
    "                \"lang\": lang,\n",
    "                \"text\": text,\n",
    "                \"urls\": expanded_urls,\n",
    "                \"domains\": domains,\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df[\"created_at_parsed\"] = df[\"created_at\"].apply(parse_created_at)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb661bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot group tweets: (152633, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>urls</th>\n",
       "      <th>domains</th>\n",
       "      <th>created_at_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>675823000747380737</td>\n",
       "      <td>3292042493</td>\n",
       "      <td>2015-12-12T23:42:14.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>_RT_ jeremycorbyn: Paris #COP21 agreement is h...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2015-12-12 23:42:14+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>675822131360440320</td>\n",
       "      <td>2237585322</td>\n",
       "      <td>2015-12-12T23:38:46.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @WRIClimate: From @ClimateMorgan -This agre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2015-12-12 23:38:46+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>675820986541973504</td>\n",
       "      <td>4010844315</td>\n",
       "      <td>2015-12-12T23:34:13.000Z</td>\n",
       "      <td>es</td>\n",
       "      <td>#sassoufit RT fernandosolanas: En breve RFI me...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2015-12-12 23:34:13+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>675820854266216448</td>\n",
       "      <td>2237585322</td>\n",
       "      <td>2015-12-12T23:33:42.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @CharlotteFrerot: This agreement should be ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2015-12-12 23:33:42+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>675819395411742722</td>\n",
       "      <td>3292042493</td>\n",
       "      <td>2015-12-12T23:27:54.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>_RT_ ApurvGupta5: BarryGardiner COP21 Today we...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2015-12-12 23:27:54+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id   author_id                created_at lang  \\\n",
       "0  675823000747380737  3292042493  2015-12-12T23:42:14.000Z   en   \n",
       "1  675822131360440320  2237585322  2015-12-12T23:38:46.000Z   en   \n",
       "2  675820986541973504  4010844315  2015-12-12T23:34:13.000Z   es   \n",
       "3  675820854266216448  2237585322  2015-12-12T23:33:42.000Z   en   \n",
       "4  675819395411742722  3292042493  2015-12-12T23:27:54.000Z   en   \n",
       "\n",
       "                                                text urls domains  \\\n",
       "0  _RT_ jeremycorbyn: Paris #COP21 agreement is h...   []      []   \n",
       "1  RT @WRIClimate: From @ClimateMorgan -This agre...   []      []   \n",
       "2  #sassoufit RT fernandosolanas: En breve RFI me...   []      []   \n",
       "3  RT @CharlotteFrerot: This agreement should be ...   []      []   \n",
       "4  _RT_ ApurvGupta5: BarryGardiner COP21 Today we...   []      []   \n",
       "\n",
       "          created_at_parsed  \n",
       "0 2015-12-12 23:42:14+00:00  \n",
       "1 2015-12-12 23:38:46+00:00  \n",
       "2 2015-12-12 23:34:13+00:00  \n",
       "3 2015-12-12 23:33:42+00:00  \n",
       "4 2015-12-12 23:27:54+00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bot group tweets\n",
    "bot_tweets_df = collect_tweets_for_users(bot_user_ids, tweets_path)\n",
    "print(\"Bot group tweets:\", bot_tweets_df.shape)\n",
    "display(bot_tweets_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ed06ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample tweets for Bot group ===\n",
      "----\n",
      "author_id: 4339043357\n",
      "created_at: 2015-12-02T20:54:36.000Z\n",
      "text: @ViHuster Bravo ! Découvrez et partagez la vidéo de l’emblème #COP21 en 3D que vous avez contribué à créer https://t.co/A3totuSTu7\n",
      "----\n",
      "author_id: 4339043357\n",
      "created_at: 2015-12-11T10:57:41.000Z\n",
      "text: @APO_source Votre Tweet façonne un emblème #COP21 en 3D. Retweetez pour le découvrir dès qu’il sera prêt ! https://t.co/zLU6Mppbcm\n",
      "----\n",
      "author_id: 4339043357\n",
      "created_at: 2015-12-02T14:32:26.000Z\n",
      "text: @unatalie Bravo ! Découvrez et partagez la vidéo de l’emblème #COP21 en 3D que vous avez contribué à créer https://t.co/A3totuSTu7\n",
      "----\n",
      "author_id: 4339043357\n",
      "created_at: 2015-12-02T15:03:24.000Z\n",
      "text: @SaraVigil_ Bravo ! Découvrez et partagez la vidéo de l’emblème #COP21 en 3D que vous avez contribué à créer https://t.co/A3totuSTu7\n",
      "----\n",
      "author_id: 4339043357\n",
      "created_at: 2015-12-02T19:10:34.000Z\n",
      "text: @arildhermstad Bravo ! Découvrez et partagez la vidéo de l’emblème #COP21 en 3D que vous avez contribué à créer https://t.co/A3totuSTu7\n"
     ]
    }
   ],
   "source": [
    "def sample_tweets(df, n=10, label=\"group\"):\n",
    "    print(f\"\\n=== Sample tweets for {label} ===\")\n",
    "    if df.empty:\n",
    "        print(\"No tweets.\")\n",
    "        return\n",
    "    for _, row in df.sample(min(n, len(df))).iterrows():\n",
    "        print(\"----\")\n",
    "        print(\"author_id:\", row[\"author_id\"])\n",
    "        print(\"created_at:\", row[\"created_at\"])\n",
    "        print(\"text:\", row[\"text\"])\n",
    "\n",
    "sample_tweets(bot_tweets_df, n=5, label=\"Bot group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76931707",
   "metadata": {},
   "source": [
    "The selected bot cluster (size = 36) shows very strong evidence of automated behavior.\n",
    "All texts originate from the same author_id.\n",
    "Highly repetitive template-based messages: Almost all tweets repeat the same short template in French (“Bravo ! Découvrez…”, “Retweetez…”, etc.) with minimal variation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66820175",
   "metadata": {},
   "source": [
    "Once we had the tweets, we linked the accounts back to the accounts.tsv file.\n",
    "This allowed us to inspect each actor’s annotated attributes(Type, Lang, and Stance) and use these annotations to qualitatively characterise the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13b22bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Bot group: accounts summary ===\n",
      "Total accounts with annotation: 2 / 36\n",
      "\n",
      "Type:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Type\n",
       "Unclear                1\n",
       "Private individuals    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lang:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lang\n",
       "N/A    1\n",
       "no     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stance:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Stance\n",
       "Unclear    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def summarize_accounts(user_ids, accounts_df, label=\"group\"):\n",
    "    user_ids = set(user_ids)\n",
    "    sub = accounts_df[accounts_df[\"author_id\"].isin(user_ids)].copy()\n",
    "    print(f\"\\n=== {label}: accounts summary ===\")\n",
    "    print(\"Total accounts with annotation:\", len(sub), \"/\", len(user_ids))\n",
    "\n",
    "    if not sub.empty:\n",
    "        print(\"\\nType:\")\n",
    "        display(sub[\"Type\"].value_counts())\n",
    "\n",
    "        print(\"\\nLang:\")\n",
    "        display(sub[\"Lang\"].value_counts())\n",
    "\n",
    "        print(\"\\nStance:\")\n",
    "        display(sub[\"Stance\"].value_counts())\n",
    "\n",
    "    return sub\n",
    "\n",
    "bot_accounts_sub = summarize_accounts(bot_user_ids, accounts_df, label=\"Bot group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3996e338",
   "metadata": {},
   "source": [
    "Low annotation coverage:\n",
    "Only 2/36 accounts have manual labels (“Unclear”), and none are labeled as legitimate organizational actors, further suggesting that these accounts were not recognized as real actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f2f932e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top 20 domains for Bot group ===\n",
      "bit.ly                                   133858\n",
      "twitter.com                              14790\n",
      "ow.ly                                    119\n",
      "youtu.be                                 85\n",
      "rfi.my                                   75\n",
      "buff.ly                                  46\n",
      "ift.tt                                   23\n",
      "goo.gl                                   18\n",
      "unfccc.int                               14\n",
      "www.facebook.com                         14\n",
      "shar.es                                  14\n",
      "fb.me                                    11\n",
      "www.rfi.fr                               11\n",
      "dai.ly                                   11\n",
      "wp.me                                    10\n",
      "www.gouvernement.fr                      10\n",
      "support.twitter.com                      10\n",
      "huff.to                                  9\n",
      "owl.li                                   9\n",
      "www.youtube.com                          8\n"
     ]
    }
   ],
   "source": [
    "def top_domains(df, top_n=20, label=\"group\"):\n",
    "    all_domains = []\n",
    "    for lst in df[\"domains\"].dropna():\n",
    "        all_domains.extend([d for d in lst if d])\n",
    "    cnt = Counter(all_domains)\n",
    "    top = cnt.most_common(top_n)\n",
    "    print(f\"\\n=== Top {top_n} domains for {label} ===\")\n",
    "    for dom, c in top:\n",
    "        print(f\"{dom:40s} {c}\")\n",
    "    return top\n",
    "\n",
    "_ = top_domains(bot_tweets_df, top_n=20, label=\"Bot group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1055cba",
   "metadata": {},
   "source": [
    "URL repetition at extreme scale:\n",
    "The group overwhelmingly posts shortened URLs (bit.ly, ow.ly), which appear more than 100k times in the group.\n",
    "This level of repetition strongly suggests automated link broadcasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ce393",
   "metadata": {},
   "source": [
    "## qualitative characterisation of Ideology group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd34091f",
   "metadata": {},
   "source": [
    "In the ideology network, we focus on the giant connected component and apply the Louvain algorithm to detect communities.\n",
    "We treat each community as a meso-level structure, and we selected community 5 (8,634 accounts) for qualitative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e624cdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected ideology community: 5\n",
      "Number of users: 8634\n",
      "Example author_ids: ['634812478', '3192259786', '2485519698', '1947834289', '2273147136', '374470274', '190883866', '3445003276', '358448639', '3369695447']\n"
     ]
    }
   ],
   "source": [
    "IDE_COMMS_PATH = DATA_DIR / \"G_ide_gc_comms.pkl\"\n",
    "with open(IDE_COMMS_PATH, \"rb\") as f:\n",
    "    ide_gc_comms = pickle.load(f)\n",
    "\n",
    "g_ide_gc_ig = ide_gc_comms.graph\n",
    "\n",
    "k_ide = 5  # select community index\n",
    "ide_vertex_indices = ide_gc_comms[k_ide]\n",
    "\n",
    "ide_user_ids = {\n",
    "    str(g_ide_gc_ig.vs[idx][\"name\"])\n",
    "    for idx in ide_vertex_indices\n",
    "}\n",
    "\n",
    "print(\"Selected ideology community:\", k_ide)\n",
    "print(\"Number of users:\", len(ide_user_ids))\n",
    "print(\"Example author_ids:\", list(ide_user_ids)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa48cca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideology group tweets: (58515, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>urls</th>\n",
       "      <th>domains</th>\n",
       "      <th>created_at_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>675827457023324160</td>\n",
       "      <td>190544832</td>\n",
       "      <td>2015-12-12T23:59:56.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @ambafrancefj: 1.5°C clearly mentioned in #...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2015-12-12 23:59:56+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>675827390971437056</td>\n",
       "      <td>190544832</td>\n",
       "      <td>2015-12-12T23:59:40.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @COP21en: .@LaurentFabius: \"I see there is ...</td>\n",
       "      <td>[https://twitter.com/COP21en/status/6757446434...</td>\n",
       "      <td>[twitter.com]</td>\n",
       "      <td>2015-12-12 23:59:40+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>675827386416541696</td>\n",
       "      <td>518918764</td>\n",
       "      <td>2015-12-12T23:59:39.000Z</td>\n",
       "      <td>es</td>\n",
       "      <td>RT @WWFnoticias: HOY, el mundo marcó el princi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2015-12-12 23:59:39+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>675827386060025857</td>\n",
       "      <td>239264304</td>\n",
       "      <td>2015-12-12T23:59:39.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>Paris climate deal welcomed in New Zealand  - ...</td>\n",
       "      <td>[https://nz.news.yahoo.com/top-stories/a/30351...</td>\n",
       "      <td>[nz.news.yahoo.com]</td>\n",
       "      <td>2015-12-12 23:59:39+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>675827385976098816</td>\n",
       "      <td>620217524</td>\n",
       "      <td>2015-12-12T23:59:39.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @JimHarris: Under Harper, Cda Was HATED for...</td>\n",
       "      <td>[http://bit.ly/1TInWBP]</td>\n",
       "      <td>[bit.ly]</td>\n",
       "      <td>2015-12-12 23:59:39+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  author_id                created_at lang  \\\n",
       "0  675827457023324160  190544832  2015-12-12T23:59:56.000Z   en   \n",
       "1  675827390971437056  190544832  2015-12-12T23:59:40.000Z   en   \n",
       "2  675827386416541696  518918764  2015-12-12T23:59:39.000Z   es   \n",
       "3  675827386060025857  239264304  2015-12-12T23:59:39.000Z   en   \n",
       "4  675827385976098816  620217524  2015-12-12T23:59:39.000Z   en   \n",
       "\n",
       "                                                text  \\\n",
       "0  RT @ambafrancefj: 1.5°C clearly mentioned in #...   \n",
       "1  RT @COP21en: .@LaurentFabius: \"I see there is ...   \n",
       "2  RT @WWFnoticias: HOY, el mundo marcó el princi...   \n",
       "3  Paris climate deal welcomed in New Zealand  - ...   \n",
       "4  RT @JimHarris: Under Harper, Cda Was HATED for...   \n",
       "\n",
       "                                                urls              domains  \\\n",
       "0                                                 []                   []   \n",
       "1  [https://twitter.com/COP21en/status/6757446434...        [twitter.com]   \n",
       "2                                                 []                   []   \n",
       "3  [https://nz.news.yahoo.com/top-stories/a/30351...  [nz.news.yahoo.com]   \n",
       "4                            [http://bit.ly/1TInWBP]             [bit.ly]   \n",
       "\n",
       "          created_at_parsed  \n",
       "0 2015-12-12 23:59:56+00:00  \n",
       "1 2015-12-12 23:59:40+00:00  \n",
       "2 2015-12-12 23:59:39+00:00  \n",
       "3 2015-12-12 23:59:39+00:00  \n",
       "4 2015-12-12 23:59:39+00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ideology group tweets\n",
    "ide_tweets_df = collect_tweets_for_users(ide_user_ids, tweets_path)\n",
    "print(\"Ideology group tweets:\", ide_tweets_df.shape)\n",
    "display(ide_tweets_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7380545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top 20 domains for Ideology group ===\n",
      "twitter.com                              23640\n",
      "bit.ly                                   5848\n",
      "ow.ly                                    1965\n",
      "goo.gl                                   1056\n",
      "buff.ly                                  672\n",
      "www.youtube.com                          388\n",
      "youtu.be                                 353\n",
      "nyti.ms                                  318\n",
      "bbc.in                                   284\n",
      "wef.ch                                   276\n",
      "u.afp.com                                265\n",
      "unfccc.int                               251\n",
      "fb.me                                    231\n",
      "unfccc6.meta-fusion.com                  222\n",
      "gu.com                                   217\n",
      "www.theguardian.com                      208\n",
      "wrld.bg                                  204\n",
      "dlvr.it                                  198\n",
      "amp.twimg.com                            179\n",
      "cnn.it                                   176\n"
     ]
    }
   ],
   "source": [
    "_ = top_domains(ide_tweets_df, top_n=20, label=\"Ideology group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b00df6",
   "metadata": {},
   "source": [
    "The top domains are news/NGO/media platforms, not dominated by a single shortener.\n",
    "This is consistent with organic user behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "551226bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ideology group: accounts summary ===\n",
      "Total accounts with annotation: 21 / 8634\n",
      "\n",
      "Type:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Type\n",
       "Advocacy actors        8\n",
       "Political actors       4\n",
       "Business actors        3\n",
       "Journalistic actors    3\n",
       "Private individuals    2\n",
       "Unclear                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lang:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lang\n",
       "en     14\n",
       "es      4\n",
       "de      1\n",
       "fr      1\n",
       "N/A     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stance:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Stance\n",
       "Unclear    11\n",
       "For        10\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ide_accounts_sub = summarize_accounts(ide_user_ids, accounts_df, label=\"Ideology group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca4ef0",
   "metadata": {},
   "source": [
    "This meso-level structure shows the characteristics of a large, heterogeneous issue community around COP21. The accounts include advocacy organisations, political actors, journalists, and individual users.\n",
    "\n",
    "Tweets are written in many languages (EN, ES, FR, DE, Farsi, Danish…), reflecting broad international participation.\n",
    "\n",
    "The stance distribution suggests that many actors support climate negotiations or share updates without explicit stance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1fcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample tweets for Ideology group ===\n",
      "----\n",
      "author_id: 15423648\n",
      "created_at: 2015-11-30T14:10:45.000Z\n",
      "text: RT @HRMirzadeh: اقتصاد نفتی مهمترین ترمز برای اقدامات دولت #ایران درباره انتشار #کربن و #تغییرات_اقلیمی است. #COP21 #climatechange\n",
      "----\n",
      "author_id: 262871846\n",
      "created_at: 2015-11-30T13:51:34.000Z\n",
      "text: RT @AFD_France: Jour J pour la @COP21 ! Où nous trouver ? https://t.co/puLqBcUVHG #Pogramme #COP21 #GoCOP21 https://t.co/QPFcGdAvFs\n",
      "----\n",
      "author_id: 17758861\n",
      "created_at: 2015-12-05T14:07:00.000Z\n",
      "text: Lederen for @WWF's #COP21-delegation @TasneemEssop : nu skal regeringerne holde fast i ambitionerne, følge videnskaben #dkgreen #dkpol\n",
      "----\n",
      "author_id: 2545900439\n",
      "created_at: 2015-12-09T01:47:56.000Z\n",
      "text: RT @ghoberg: Freaky. I did a lot of reading before #COP21 and there was no indication that US, China, Canada would support 1.5,  https://t.…\n",
      "----\n",
      "author_id: 4163221342\n",
      "created_at: 2015-12-04T17:03:50.000Z\n",
      "text: RT @oxfamgb: This is our global warning - we cannot ignore it. Retweet to show politicians we are watching #COP21 #eyesonParis https://t.co…\n"
     ]
    }
   ],
   "source": [
    "sample_tweets(ide_tweets_df, n=5, label=\"Ideology group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a52351",
   "metadata": {},
   "source": [
    "The ideology community behaves like a genuine public/organisational conversation cluster, not an automated bot group."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ae-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
