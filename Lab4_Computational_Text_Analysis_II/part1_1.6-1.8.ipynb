{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6bed6e9",
   "metadata": {},
   "source": [
    "## 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b20802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../data/\")\n",
    "\n",
    "author_docs = pd.read_pickle(DATA_DIR / \"author_docs_with_tokens.pkl\")\n",
    "docs_tokens_nostop = author_docs[\"tokens_nostop\"].tolist()\n",
    "docs_tokens_keepstop = author_docs[\"tokens_keepstop\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dab702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据 task 建议, 用保留 stopwords 的 tokens\n",
    "docs_tokens = author_docs[\"tokens_keepstop\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ab587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp38-cp38-macosx_10_9_x86_64.whl (24.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/yuezhou/opt/anaconda3/envs/ae-data/lib/python3.8/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/yuezhou/opt/anaconda3/envs/ae-data/lib/python3.8/site-packages (from gensim) (1.24.4)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-7.3.1-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wrapt\n",
      "  Downloading wrapt-2.0.1-cp38-cp38-macosx_10_9_x86_64.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wrapt, smart-open, gensim\n",
      "Successfully installed gensim-4.3.3 smart-open-7.3.1 wrapt-2.0.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c91fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "def run_lda(alpha, beta, K=4):\n",
    "    model = LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=K,\n",
    "        alpha=alpha,\n",
    "        eta=beta,     # gensim 用 eta 表示 Beta\n",
    "        random_state=42,\n",
    "        passes=20\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85f07925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 dictionary & corpus\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "dictionary = Dictionary(docs_tokens)\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.95)\n",
    "\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea107bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter ranges\n",
    "alpha_low  = 0.01\n",
    "alpha_high = 1.0\n",
    "\n",
    "beta_low   = 0.01\n",
    "beta_high  = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1700b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 symmetric runs\n",
    "model_LL = run_lda(alpha_low,  beta_low)   # Low α, Low β\n",
    "model_LH = run_lda(alpha_low,  beta_high)  # Low α, High β\n",
    "model_HL = run_lda(alpha_high, beta_low)   # High α, Low β\n",
    "model_HH = run_lda(alpha_high, beta_high)  # High α, High β\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1574eeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Low α, Low β =====\n",
      "Topic 0: 0.051*\"the\" + 0.033*\"climate\" + 0.022*\"paris\" + 0.020*\"for\" + 0.015*\"and\" + 0.009*\"climatechange\" + 0.009*\"from\" + 0.008*\"are\" + 0.007*\"change\" + 0.006*\"deal\"\n",
      "Topic 1: 0.043*\"the\" + 0.021*\"for\" + 0.019*\"climate\" + 0.015*\"amp\" + 0.014*\"and\" + 0.010*\"our\" + 0.009*\"from\" + 0.008*\"climatechange\" + 0.008*\"paris\" + 0.008*\"are\"\n",
      "Topic 2: 0.039*\"climatechange\" + 0.034*\"the\" + 0.018*\"for\" + 0.018*\"amp\" + 0.018*\"copparis\" + 0.014*\"freepresidentnasheed\" + 0.013*\"climate\" + 0.013*\"maldives\" + 0.012*\"and\" + 0.011*\"behind\"\n",
      "Topic 3: 0.038*\"climate\" + 0.027*\"the\" + 0.026*\"climatechange\" + 0.024*\"cdnpoli\" + 0.016*\"amp\" + 0.014*\"design\" + 0.014*\"change\" + 0.014*\"green\" + 0.010*\"for\" + 0.009*\"actonclimate\"\n",
      "\n",
      "===== Low α, High β =====\n",
      "Topic 0: 0.049*\"the\" + 0.032*\"climate\" + 0.020*\"paris\" + 0.019*\"for\" + 0.014*\"and\" + 0.010*\"climatechange\" + 0.008*\"from\" + 0.007*\"are\" + 0.007*\"change\" + 0.006*\"amp\"\n",
      "Topic 1: 0.040*\"the\" + 0.020*\"climate\" + 0.019*\"for\" + 0.015*\"amp\" + 0.013*\"and\" + 0.010*\"climatechange\" + 0.009*\"our\" + 0.008*\"from\" + 0.008*\"paris\" + 0.007*\"are\"\n",
      "Topic 2: 0.026*\"climatechange\" + 0.022*\"the\" + 0.016*\"copparis\" + 0.014*\"freepresidentnasheed\" + 0.012*\"maldives\" + 0.012*\"for\" + 0.012*\"amp\" + 0.011*\"climatehero\" + 0.011*\"behind\" + 0.011*\"bars\"\n",
      "Topic 3: 0.025*\"cdnpoli\" + 0.017*\"climatechange\" + 0.015*\"design\" + 0.012*\"green\" + 0.012*\"climate\" + 0.011*\"the\" + 0.009*\"birdstellus\" + 0.008*\"nuclear\" + 0.008*\"amp\" + 0.008*\"change\"\n",
      "\n",
      "===== High α, Low β =====\n",
      "Topic 0: 0.051*\"the\" + 0.034*\"climate\" + 0.022*\"paris\" + 0.020*\"for\" + 0.015*\"and\" + 0.009*\"from\" + 0.008*\"climatechange\" + 0.008*\"are\" + 0.007*\"change\" + 0.007*\"deal\"\n",
      "Topic 1: 0.043*\"the\" + 0.021*\"for\" + 0.018*\"climate\" + 0.014*\"amp\" + 0.014*\"and\" + 0.010*\"our\" + 0.009*\"from\" + 0.008*\"paris\" + 0.008*\"are\" + 0.008*\"climatechange\"\n",
      "Topic 2: 0.040*\"climatechange\" + 0.035*\"the\" + 0.018*\"for\" + 0.018*\"amp\" + 0.017*\"copparis\" + 0.013*\"freepresidentnasheed\" + 0.012*\"climate\" + 0.012*\"and\" + 0.012*\"maldives\" + 0.011*\"behind\"\n",
      "Topic 3: 0.038*\"climate\" + 0.028*\"the\" + 0.027*\"climatechange\" + 0.021*\"cdnpoli\" + 0.016*\"amp\" + 0.014*\"change\" + 0.014*\"green\" + 0.013*\"design\" + 0.010*\"for\" + 0.009*\"actonclimate\"\n",
      "\n",
      "===== High α, High β =====\n",
      "Topic 0: 0.049*\"the\" + 0.032*\"climate\" + 0.021*\"paris\" + 0.019*\"for\" + 0.014*\"and\" + 0.009*\"climatechange\" + 0.008*\"from\" + 0.007*\"are\" + 0.007*\"change\" + 0.006*\"amp\"\n",
      "Topic 1: 0.040*\"the\" + 0.020*\"climate\" + 0.020*\"for\" + 0.015*\"amp\" + 0.013*\"and\" + 0.009*\"our\" + 0.009*\"climatechange\" + 0.008*\"from\" + 0.008*\"paris\" + 0.007*\"are\"\n",
      "Topic 2: 0.029*\"climatechange\" + 0.022*\"the\" + 0.017*\"copparis\" + 0.013*\"freepresidentnasheed\" + 0.012*\"for\" + 0.012*\"maldives\" + 0.012*\"amp\" + 0.011*\"behind\" + 0.011*\"climatehero\" + 0.010*\"bars\"\n",
      "Topic 3: 0.024*\"cdnpoli\" + 0.017*\"climatechange\" + 0.014*\"design\" + 0.013*\"climate\" + 0.012*\"green\" + 0.012*\"the\" + 0.009*\"amp\" + 0.008*\"nuclear\" + 0.008*\"change\" + 0.008*\"birdstellus\"\n"
     ]
    }
   ],
   "source": [
    "def print_topics(model, label):\n",
    "    print(f\"\\n===== {label} =====\")\n",
    "    for tid, words in model.print_topics(num_words=10):\n",
    "        print(f\"Topic {tid}: {words}\")\n",
    "\n",
    "print_topics(model_LL, \"Low α, Low β\")\n",
    "print_topics(model_LH, \"Low α, High β\")\n",
    "print_topics(model_HL, \"High α, Low β\")\n",
    "print_topics(model_HH, \"High α, High β\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9483989",
   "metadata": {},
   "source": [
    "The corpus is highly homogeneous\n",
    "\n",
    "the dataset is:\n",
    "\n",
    "small,\n",
    "\n",
    "short texts (authors aggregated into small documents),\n",
    "\n",
    "highly homogeneous (everyone talks about climate politics).\n",
    "\n",
    "Therefore:\n",
    "\n",
    "LDA cannot separate topics strongly,\n",
    "\n",
    "α changes little in top-words,\n",
    "\n",
    "β only slightly changes topic smoothness,\n",
    "\n",
    "asymmetric α still shows the clearest effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d4dd3",
   "metadata": {},
   "source": [
    "Low β (0.01)  topics are sharper and more peaked.\n",
    "Some words such as “climatechange”, “copparis”, “climate” become very dominant.\n",
    "\n",
    "High β (1.0)  topics become more uniform, with more medium-probability words.\n",
    "Rare words almost disappear; common words (the, climate, for, and) appear more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b13ddeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Asymmetric α (Beta low) =====\n",
      "Topic 0: 0.051*\"the\" + 0.034*\"climate\" + 0.023*\"paris\" + 0.020*\"for\" + 0.015*\"and\" + 0.009*\"from\" + 0.007*\"are\" + 0.007*\"climatechange\" + 0.007*\"deal\" + 0.007*\"change\"\n",
      "Topic 1: 0.044*\"the\" + 0.022*\"for\" + 0.018*\"climate\" + 0.014*\"and\" + 0.014*\"amp\" + 0.010*\"our\" + 0.009*\"paris\" + 0.009*\"from\" + 0.008*\"are\" + 0.008*\"with\"\n",
      "Topic 2: 0.036*\"the\" + 0.034*\"climatechange\" + 0.019*\"for\" + 0.018*\"amp\" + 0.017*\"copparis\" + 0.013*\"and\" + 0.012*\"freepresidentnasheed\" + 0.012*\"maldives\" + 0.011*\"our\" + 0.011*\"behind\"\n",
      "Topic 3: 0.035*\"climate\" + 0.034*\"the\" + 0.028*\"climatechange\" + 0.016*\"amp\" + 0.013*\"change\" + 0.012*\"cdnpoli\" + 0.012*\"for\" + 0.009*\"green\" + 0.008*\"design\" + 0.007*\"are\"\n"
     ]
    }
   ],
   "source": [
    "# Asymmetric α\n",
    "# when k=4\n",
    "asym_alpha = [0.1, 0.5, 1.0, 2.0]\n",
    "model_asym = run_lda(asym_alpha, beta_low)\n",
    "\n",
    "print_topics(model_asym, \"Asymmetric α (Beta low)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c26dc53",
   "metadata": {},
   "source": [
    "## 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96a293fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: <gensim.models.ldamodel.LdaModel at 0x1acf4a430>,\n",
       " 10: <gensim.models.ldamodel.LdaModel at 0x1ae035e50>,\n",
       " 20: <gensim.models.ldamodel.LdaModel at 0x19d3d3cd0>}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练多个k的LDA模型\n",
    "from gensim import corpora, models\n",
    "\n",
    "# 使用 NOT STOP 的或 KEEP STOP 的都行，但任务 1.6 建议保留停用词\n",
    "tokens_list = docs_tokens_keepstop  \n",
    "\n",
    "# 词典与语料\n",
    "dictionary = corpora.Dictionary(tokens_list)\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in tokens_list]\n",
    "\n",
    "def train_lda(K, alpha='symmetric', eta='auto', passes=10, random_state=42):\n",
    "    lda = models.LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=K,\n",
    "        alpha=alpha,\n",
    "        eta=eta,\n",
    "        random_state=random_state,\n",
    "        passes=passes\n",
    "    )\n",
    "    return lda\n",
    "\n",
    "# 选择几个 K\n",
    "K_list = [5, 10, 20]\n",
    "lda_models = {K: train_lda(K) for K in K_list}\n",
    "\n",
    "lda_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3204887d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../data/topic_similarity_pairs.csv')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机抽n对作者文档\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "N = 15\n",
    "random.seed(0)\n",
    "\n",
    "num_docs = len(author_docs)\n",
    "pairs = set()\n",
    "\n",
    "while len(pairs) < N:\n",
    "    i, j = random.sample(range(num_docs), 2)\n",
    "    if i > j:\n",
    "        i, j = j, i\n",
    "    pairs.add((i, j))\n",
    "\n",
    "rows = []\n",
    "for idx, (i, j) in enumerate(pairs):\n",
    "    doc_i = author_docs.iloc[i]\n",
    "    doc_j = author_docs.iloc[j]\n",
    "    rows.append({\n",
    "        \"pair_id\": idx,\n",
    "        \"doc_i_index\": i,\n",
    "        \"doc_j_index\": j,\n",
    "        \"author_i\": doc_i[\"author_id\"],\n",
    "        \"author_j\": doc_j[\"author_id\"],\n",
    "        \"text_i\": doc_i[\"full_text\"][:400],\n",
    "        \"text_j\": doc_j[\"full_text\"][:400],\n",
    "        \"label\": \"\"  # 你之后手动填 0/1/2\n",
    "    })\n",
    "\n",
    "pairs_df = pd.DataFrame(rows)\n",
    "\n",
    "out_path = Path(\"../data/topic_similarity_pairs.csv\")\n",
    "pairs_df.to_csv(out_path, index=False)\n",
    "\n",
    "out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c726bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算文档–topic 分布（对齐你的 corpus）\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def doc_topic_matrix(lda_model, corpus, K):\n",
    "    theta = np.zeros((len(corpus), K))\n",
    "    for d, bow in enumerate(corpus):\n",
    "        for topic_id, prob in lda_model.get_document_topics(bow):\n",
    "            theta[d, topic_id] = prob\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9db51d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入你的人工标注\n",
    "labels_df = pd.read_csv(\"../data/topic_similarity_pairs.csv\")\n",
    "labels_df[\"label\"] = labels_df[\"label\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3832c4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>label</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.256352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   K  pair_id  label       sim\n",
       "0  5        0      2  0.256352\n",
       "1  5        1      2  0.999775\n",
       "2  5        2      2  0.996670\n",
       "3  5        3      1  0.025457\n",
       "4  5        4      1  0.999625"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for K, lda in lda_models.items():\n",
    "    theta = doc_topic_matrix(lda, corpus, K)\n",
    "\n",
    "    tmp_rows = []\n",
    "    for _, row in labels_df.iterrows():\n",
    "        i = int(row[\"doc_i_index\"])\n",
    "        j = int(row[\"doc_j_index\"])\n",
    "        label = int(row[\"label\"])\n",
    "\n",
    "        sim = cosine_similarity(theta[i].reshape(1, -1),\n",
    "                                theta[j].reshape(1, -1))[0, 0]\n",
    "\n",
    "        tmp_rows.append({\n",
    "            \"K\": K,\n",
    "            \"pair_id\": row[\"pair_id\"],\n",
    "            \"label\": label,\n",
    "            \"sim\": sim\n",
    "        })\n",
    "    tmp = pd.DataFrame(tmp_rows)\n",
    "    all_results.append(tmp)\n",
    "\n",
    "results_df = pd.concat(all_results, ignore_index=True)\n",
    "results_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a99919af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>label</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458135</td>\n",
       "      <td>0.647901</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.652810</td>\n",
       "      <td>0.406116</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.551745</td>\n",
       "      <td>0.496240</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139570</td>\n",
       "      <td>0.197382</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.542684</td>\n",
       "      <td>0.508547</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.347679</td>\n",
       "      <td>0.363524</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.224758</td>\n",
       "      <td>0.317856</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514330</td>\n",
       "      <td>0.488818</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.397380</td>\n",
       "      <td>0.480414</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    K  label      mean       std  count\n",
       "0   5      0  0.458135  0.647901      2\n",
       "1   5      1  0.652810  0.406116      7\n",
       "2   5      2  0.551745  0.496240      6\n",
       "3  10      0  0.139570  0.197382      2\n",
       "4  10      1  0.542684  0.508547      7\n",
       "5  10      2  0.347679  0.363524      6\n",
       "6  20      0  0.224758  0.317856      2\n",
       "7  20      1  0.514330  0.488818      7\n",
       "8  20      2  0.397380  0.480414      6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = (\n",
    "    results_df\n",
    "    .groupby([\"K\", \"label\"])[\"sim\"]\n",
    "    .agg([\"mean\", \"std\", \"count\"])\n",
    "    .reset_index()\n",
    ")\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6948422",
   "metadata": {},
   "source": [
    "We found that the similarity estimates  depend on the choice of K.\n",
    "\n",
    "With K = 5, topics were too coarse and many pairs—including unrelated ones—received high similarity.\n",
    "\n",
    "With K = 20, topics became too fragmented, increasing noise and pushing similarities toward the middle.\n",
    "\n",
    "K = 10 provided the most reasonable separation between unrelated and somewhat related pairs, although the model still struggled to distinguish between \"somewhat related\" and \"very related\".\n",
    "\n",
    "This shows the difficulty of adapting clustering‐style evaluation to mixed‐membership models, as LDA’s topic proportions do not align perfectly with human semantic judgments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4718bacf",
   "metadata": {},
   "source": [
    "## 1.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301621e7",
   "metadata": {},
   "source": [
    "Associate topic results with the author's metadata (Type or Stance) to determine whether different groups exhibit preferences for certain topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b45d2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "dictionary = Dictionary(docs_tokens_keepstop)\n",
    "\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs_tokens_keepstop]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ed77b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "K = 10\n",
    "\n",
    "lda10 = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=K,\n",
    "    passes=10,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727484b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the author's topic distribution\n",
    "topic_dist = [\n",
    "    lda10.get_document_topics(bow, minimum_probability=0)\n",
    "    for bow in corpus\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "faadda03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_docs = len(topic_dist)\n",
    "topic_matrix = np.zeros((n_docs, K))\n",
    "\n",
    "for i, dist in enumerate(topic_dist):\n",
    "    for topic_id, prob in dist:\n",
    "        topic_matrix[i, topic_id] = prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aabfcdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge into author_docs (because it contains Type / Stance)\n",
    "df = author_docs.copy()\n",
    "for k in range(K):\n",
    "    df[f\"topic_{k}\"] = topic_matrix[:, k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "994877e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stance</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Against</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.213090</td>\n",
       "      <td>0.086139</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.700556</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>For</th>\n",
       "      <td>0.026292</td>\n",
       "      <td>0.088645</td>\n",
       "      <td>0.458618</td>\n",
       "      <td>0.012710</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.144121</td>\n",
       "      <td>0.008970</td>\n",
       "      <td>0.095286</td>\n",
       "      <td>0.137289</td>\n",
       "      <td>0.023164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unclear</th>\n",
       "      <td>0.028752</td>\n",
       "      <td>0.116330</td>\n",
       "      <td>0.453647</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.130091</td>\n",
       "      <td>0.023356</td>\n",
       "      <td>0.078936</td>\n",
       "      <td>0.106604</td>\n",
       "      <td>0.033420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          topic_0   topic_1   topic_2   topic_3   topic_4   topic_5   topic_6  \\\n",
       "Stance                                                                          \n",
       "Against  0.000021  0.213090  0.086139  0.000021  0.000021  0.000091  0.000021   \n",
       "For      0.026292  0.088645  0.458618  0.012710  0.004905  0.144121  0.008970   \n",
       "Unclear  0.028752  0.116330  0.453647  0.022700  0.006164  0.130091  0.023356   \n",
       "\n",
       "          topic_7   topic_8   topic_9  \n",
       "Stance                                 \n",
       "Against  0.000021  0.700556  0.000021  \n",
       "For      0.095286  0.137289  0.023164  \n",
       "Unclear  0.078936  0.106604  0.033420  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate intergroup differences by type or stance\n",
    "# by type\n",
    "group_stats = df.groupby(\"Type\")[ [f\"topic_{k}\" for k in range(K)] ].mean()\n",
    "group_stats\n",
    "\n",
    "# by stance\n",
    "stance_stats = df.groupby(\"Stance\")[ [f\"topic_{k}\" for k in range(K)] ].mean()\n",
    "stance_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89731e4",
   "metadata": {},
   "source": [
    "Based on an LDA model with K=10, I calculated the average topic distribution for documents across different stances (For / Against / Unclear). The results reveal that certain topics exhibit distinct preferences across different stances.\n",
    "\n",
    "The “Against” group shows high concentration in topic_8 (0.70). Opponents tend to talk about one very specific theme, with extremely little thematic diversity.\n",
    "\n",
    "The “For” group primarily focuses on topic_2 (0.46) and topic_5 (0.14).\n",
    "\n",
    "Unclear accounts behave like a mixture of For and casual observers"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
