{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0686f52d",
   "metadata": {},
   "source": [
    "# Network Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdaadf2",
   "metadata": {},
   "source": [
    "Network data: graphs with retweet and reply networks, where the vertices are accounts and the edges indicate that one account has replied to another, or retweeted a tweet from another. Think about what vertex and/or edge attributes could be useful to store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6250f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c2635e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5410c0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to parse ISO 8601 timestamps\n",
    "def parse_created_at(ts):\n",
    "    if not ts:\n",
    "        return None\n",
    "    # \"2015-12-12T23:59:59.000Z\"\n",
    "    try:\n",
    "        return datetime.fromisoformat(ts.replace(\"Z\", \"+00:00\"))\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a917835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_path = \"../data/tweets.dat\"\n",
    "tweets = []\n",
    "\n",
    "with open(tweets_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for ln, line in enumerate(f, start=1):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            tw = json.loads(line)\n",
    "        except json.JSONDecodeError:\n",
    "            # skip malformed lines\n",
    "            continue\n",
    "\n",
    "        # basic fields\n",
    "        tweet_id = str(tw.get(\"id\", \"\")).strip()\n",
    "        author_id = str(tw.get(\"author_id\", \"\")).strip()\n",
    "        created_at = parse_created_at(tw.get(\"created_at\"))\n",
    "        lang = tw.get(\"lang\")\n",
    "        \n",
    "        # interaction fields\n",
    "        referenced_tweets = tw.get(\"referenced_tweets\")\n",
    "        in_reply_to_user_id = tw.get(\"in_reply_to_user_id\")\n",
    "\n",
    "        # public metrics\n",
    "        metrics = tw.get(\"public_metrics\") or {}\n",
    "        # retweets = metrics.get(\"retweet_count\")\n",
    "        # replies = metrics.get(\"reply_count\")\n",
    "        # likes = metrics.get(\"like_count\")\n",
    "        # quotes = metrics.get(\"quote_count\")\n",
    "\n",
    "        \n",
    "        # gather tweet record\n",
    "        tweets.append({\n",
    "            \"id\": tweet_id,\n",
    "            \"author_id\": author_id,\n",
    "            \"created_at\": created_at,\n",
    "            \"date\": created_at.date().isoformat() if created_at else None,\n",
    "            \"lang\": lang,\n",
    "            \n",
    "            \"referenced_tweets\": referenced_tweets,\n",
    "            \"in_reply_to_user_id\": in_reply_to_user_id,\n",
    "            \n",
    "            # \"retweet_count\": retweets,\n",
    "            # \"reply_count\": replies,\n",
    "            # \"like_count\": likes,\n",
    "            # \"quote_count\": quotes,\n",
    "            \"public_metrics\": metrics # 保留完整的 metrics 字典，方便后续操作\n",
    "        })\n",
    "\n",
    "all_records = pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00923058",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a945825",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d3c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts = pd.read_csv(r\"../data/accounts.tsv\", sep='\\t', dtype={'author_id': str})\n",
    "accounts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb8ac1",
   "metadata": {},
   "source": [
    "## Network Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17108a46",
   "metadata": {},
   "source": [
    "* Nodes(accounts.tsv): accounts，metrics: Type\tLang\tStance\n",
    "\n",
    "* Edges(tweets.dat): tweets, type: reply / retweet，metrics: public_metrics - 'retweet_count', 'reply_count', 'like_count', 'quote_count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d70ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize graph\n",
    "G = nx.MultiDiGraph()\n",
    "\n",
    "## Add nodes\n",
    "known_user_ids = set(accounts['author_id'].unique()) # author IDs in accounts dataset\n",
    "\n",
    "node_list = [\n",
    "    (row['author_id'], {'user_type': row['Type'], 'lang': row['Lang'], 'stance': row['Stance']}) \n",
    "    for idx, row in accounts.iterrows()\n",
    "]\n",
    "G.add_nodes_from(node_list)\n",
    "\n",
    "\n",
    "## Add edges\n",
    "# prepare mapping dataframe\n",
    "tweet_author_df = all_records[['id', 'author_id']].rename(columns={'id': 'target_tweet_id', 'author_id': 'target_author_id'})\n",
    "\n",
    "retweet_edges_data = []\n",
    "reply_edges_data = []\n",
    "\n",
    "# extract data from original records\n",
    "for idx, row in all_records.iterrows():\n",
    "    focal_node = row['author_id']\n",
    "    \n",
    "    # skip if focal_node not in known_user_ids\n",
    "    if focal_node not in known_user_ids:\n",
    "        continue\n",
    "        \n",
    "    public_metrics = row['public_metrics']\n",
    "    edge_attrs = {\n",
    "        'retweet_count': public_metrics['retweet_count'],\n",
    "        'reply_count': public_metrics['reply_count'],\n",
    "        'like_count': public_metrics['like_count'],\n",
    "        'quote_count': public_metrics['quote_count']\n",
    "    }\n",
    "    \n",
    "    # extract retweet edges\n",
    "    if isinstance(row['referenced_tweets'], list):\n",
    "        for ref_tweet in row['referenced_tweets']:\n",
    "            if ref_tweet.get('type') == 'retweeted':\n",
    "                # gather data for batch processing\n",
    "                retweet_edges_data.append({\n",
    "                    'source_author_id': focal_node,\n",
    "                    'target_tweet_id': ref_tweet['id'], # JOIN key\n",
    "                    **edge_attrs\n",
    "                })\n",
    "\n",
    "    # extract reply edges\n",
    "    target_node = row.get('in_reply_to_user_id')\n",
    "    if target_node and target_node in known_user_ids: # check if target user is in known_user_ids\n",
    "        attrs = {'type': 'reply', **edge_attrs}\n",
    "        reply_edges_data.append((focal_node, target_node, attrs))\n",
    "\n",
    "\n",
    "# map retweet edges to author IDs in batch\n",
    "if retweet_edges_data:\n",
    "    retweet_df = pd.DataFrame(retweet_edges_data)\n",
    "    \n",
    "    # Merge: map target tweet IDs to author IDs\n",
    "    merged_retweet_df = pd.merge(\n",
    "        retweet_df, \n",
    "        tweet_author_df, \n",
    "        on='target_tweet_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # ensure target author ID exists\n",
    "    final_retweet_edges = merged_retweet_df[merged_retweet_df['target_author_id'].notna()]\n",
    "    \n",
    "    # ensure author IDs are in accounts dataset\n",
    "    final_retweet_edges = final_retweet_edges[\n",
    "        final_retweet_edges['target_author_id'].isin(known_user_ids)\n",
    "    ]\n",
    "    \n",
    "    # add edges to graph\n",
    "    batch_retweet_edges = []\n",
    "    for _, row in final_retweet_edges.iterrows():\n",
    "        u = row['source_author_id']\n",
    "        v = row['target_author_id']\n",
    "        \n",
    "        # extract edge attributes\n",
    "        attrs = row.drop(['source_author_id', 'target_tweet_id', 'target_author_id']).to_dict()\n",
    "        attrs['type'] = 'retweet' \n",
    "        \n",
    "        batch_retweet_edges.append((u, v, attrs))\n",
    "    \n",
    "    G.add_edges_from(batch_retweet_edges)\n",
    "\n",
    "# add reply edges to graph\n",
    "G.add_edges_from(reply_edges_data)\n",
    "\n",
    "print(f\"Successfully constructed the graph G.\")\n",
    "print(f\"Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b93ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.edges(data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c660262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check parallel edges between two nodes\n",
    "u = '8508262'\n",
    "v = '88047464'\n",
    "\n",
    "print(f\"Edges between {u} and {v}:\")\n",
    "\n",
    "# require G.get_edge_data(u, v) to return a dict where key is the unique identifier of the edge\n",
    "edge_dict = G.get_edge_data(u, v)\n",
    "\n",
    "if edge_dict:\n",
    "    for key, data in edge_dict.items():\n",
    "        print(f\"Key: {key}, Type: {data.get('type')}, Metrics: {data.get('retweet_count')}, ...\")\n",
    "else:\n",
    "    print(\"No edges found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93068bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save graph data\n",
    "file_path_pkl = 'network_data.pkl'\n",
    "with open(file_path_pkl, 'wb') as f: # 注意 'wb' (写入二进制)\n",
    "    pickle.dump(G, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf4a921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph data\n",
    "import pickle\n",
    "file_path_pkl = 'network_data.pkl'\n",
    "with open(file_path_pkl, 'rb') as f: # 注意 'rb' (读取二进制)\n",
    "    G_loaded_pkl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07834e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_loaded_pkl.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ffd7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_loaded_pkl.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b5c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the network graph\n",
    "# plt.figure(figsize=(12,12))\n",
    "# pos = nx.spring_layout(G_loaded_pkl, k=0.15, iterations=20) # 使用 G_loaded_pkl 而不是旧的 G\n",
    "\n",
    "\n",
    "# nx.draw(\n",
    "#     G_loaded_pkl, \n",
    "#     pos,\n",
    "#     with_labels=True, \n",
    "#     node_size=500, \n",
    "#     node_color='lightblue', \n",
    "#     font_size=10, \n",
    "#     font_color='black', \n",
    "#     font_weight='bold', \n",
    "#     edge_color='gray'\n",
    "# )\n",
    "# plt.title(\"Loaded Graph Visualization\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ae-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
