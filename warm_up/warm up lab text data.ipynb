{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "037138e1",
   "metadata": {},
   "source": [
    "# Text data generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fc2a44",
   "metadata": {},
   "source": [
    "## 1. 读取推文信息，生成用于时间主题分析数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeec253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 推文数据集 ---\n",
      "             tweet_id   author_id  \\\n",
      "0  675827469119832066  1011975294   \n",
      "1  675827469006581760   255144027   \n",
      "2  675827468775718912   214748274   \n",
      "3  675827465378504705   449273927   \n",
      "4  675827465336434688  1601937732   \n",
      "\n",
      "                                          tweet_text posting_date language  \\\n",
      "0  RT @MinisterTdB: Climate change won’t stop ove...   2015-12-12       en   \n",
      "1  RT @LaurenceTubiana: I just can believe it !we...   2015-12-12       en   \n",
      "2  RT @COP21en: We did it! #ParisAgreement is ado...   2015-12-12       en   \n",
      "3  RT @TheGlobalGoals: Incredible news for our wo...   2015-12-12       en   \n",
      "4  RT @StopShenhua: “The people’s resolve is such...   2015-12-12       en   \n",
      "\n",
      "   retweet_count  favorite_count  \n",
      "0            107               0  \n",
      "1            109               0  \n",
      "2           1204               0  \n",
      "3            110               0  \n",
      "4             49               0  \n",
      "\n",
      "总记录数: 2260916\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "os.chdir(\"D:/uppsala/16. data of social mining/data\")\n",
    "\n",
    "# 文件名为 'tweets.dat'\n",
    "file_path = 'tweets.dat'\n",
    "\n",
    "# 存储提取出的推文数据的列表\n",
    "tweet_records = []\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        # 逐行读取文件\n",
    "        for line in f:\n",
    "            # 1. 解析每一行为一个 JSON 对象\n",
    "            try:\n",
    "                tweet_json = json.loads(line.strip())\n",
    "            except json.JSONDecodeError:\n",
    "                # 简单地跳过格式错误的行\n",
    "                print(f\"Skipping badly formatted line: {line[:50]}...\")\n",
    "                continue\n",
    "\n",
    "            # 2. 提取所需的字段\n",
    "            tweet_id = tweet_json.get('id')\n",
    "            author_id = tweet_json.get('author_id')\n",
    "            text = tweet_json.get('text')\n",
    "            created_at_str = tweet_json.get('created_at') # 格式如 \"2015-12-12T23:59:59.000Z\"\n",
    "            language = tweet_json.get(\"lang\")\n",
    "            metrics = tweet_json.get(\"public_metrics\", {})\n",
    "            retweet_count = metrics.get(\"retweet_count\", 0)\n",
    "            favorite_count = metrics.get(\"like_count\", 0)\n",
    "           \n",
    "            # 3. 提取日期部分 (YYYY-MM-DD)\n",
    "            # 仅取 'T' 之前的部分即为日期\n",
    "            posting_date = created_at_str.split('T')[0] if created_at_str else None\n",
    "\n",
    "            # 收集数据\n",
    "            tweet_records.append({\n",
    "                'tweet_id': tweet_id,\n",
    "                'author_id': author_id,\n",
    "                'tweet_text': text,\n",
    "                'posting_date': posting_date,\n",
    "                'language': language,\n",
    "                'retweet_count': retweet_count,\n",
    "                'favorite_count': favorite_count\n",
    "            })\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "    # 如果文件不存在，您可以跳过这一步或加载一个模拟数据\n",
    "    # return None\n",
    "\n",
    "# 4. 转换为 Pandas DataFrame\n",
    "tweets= pd.DataFrame(tweet_records)\n",
    "\n",
    "# 查看结果\n",
    "print(\"--- 推文数据集 ---\")\n",
    "print(tweets.head())\n",
    "print(f\"\\n总记录数: {len(tweets)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d95da775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posting_date\n",
      "2015-11-30    353140\n",
      "2015-12-01    219577\n",
      "2015-12-02    226315\n",
      "2015-12-03    199680\n",
      "2015-12-04    151656\n",
      "2015-12-05    103554\n",
      "2015-12-06     74992\n",
      "2015-12-07    129884\n",
      "2015-12-08    125392\n",
      "2015-12-09    137159\n",
      "2015-12-10    118877\n",
      "2015-12-11    118304\n",
      "2015-12-12    302386\n",
      "Name: count, dtype: int64\n",
      "总推文数量: 2260916\n"
     ]
    }
   ],
   "source": [
    "print(tweets['posting_date'].value_counts().sort_index())\n",
    "total_tweets = tweets['posting_date'].value_counts().sum()\n",
    "print(f\"总推文数量: {total_tweets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12abd1d",
   "metadata": {},
   "source": [
    "## 2.生成推文 + 账户信息的数据集\n",
    "\n",
    "* 为推文添加发布者的账户的信息：语言（language）、类型（type）和立场（stance）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c53e8825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已载入  accounts.tsv\n",
      "             author_id                 Type account_language Stance\n",
      "0              8508262  Private individuals               fr    For\n",
      "1           3297659759      Advocacy actors               es    For\n",
      "2  1351436889316683778  Journalistic actors               en    For\n",
      "3            259352661      Advocacy actors               en    For\n",
      "4             17158610      Advocacy actors               en    For\n",
      "(1936, 4)\n"
     ]
    }
   ],
   "source": [
    "accounts = pd.read_csv(\"accounts.tsv\", sep=\"\\t\", dtype={\"author_id\": str})\n",
    "# 重命名 accounts的 Lang 字段为 account_language，和 tweets 数据框中的 language 以示区别\n",
    "\n",
    "accounts.rename(columns={\"Lang\": \"account_language\"}, inplace=True)\n",
    "\n",
    "print(\"✅ 已载入  accounts.tsv\")\n",
    "print( accounts.head(5))\n",
    "print( accounts.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be1a6c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 合并后的数据集 ---\n",
      "             tweet_id   author_id  \\\n",
      "0  675827426363121664  2350315591   \n",
      "1  675827386416541696   518918764   \n",
      "2  675827278295777280   314125926   \n",
      "3  675827253540954112   786625296   \n",
      "4  675827250982428673   786625296   \n",
      "\n",
      "                                          tweet_text posting_date language  \\\n",
      "0  RT @LaurenceTubiana: I just can believe it !we...   2015-12-12       en   \n",
      "1  RT @WWFnoticias: HOY, el mundo marcó el princi...   2015-12-12       es   \n",
      "2  RT @paris_climate: The #Paris agreement means ...   2015-12-12       en   \n",
      "3  (La Nouvelle République):#COP21: Un coup de ma...   2015-12-12       fr   \n",
      "4  (La Provence):#COP21: Un coup de marteau et to...   2015-12-12       fr   \n",
      "\n",
      "   retweet_count  favorite_count                 Type account_language  \\\n",
      "0            109               0     Political actors               en   \n",
      "1            111               0      Advocacy actors               es   \n",
      "2             63               0      Advocacy actors               en   \n",
      "3              0               0  Journalistic actors               fr   \n",
      "4              0               0  Journalistic actors               fr   \n",
      "\n",
      "    Stance  \n",
      "0      For  \n",
      "1      For  \n",
      "2      For  \n",
      "3  Unclear  \n",
      "4  Unclear  \n",
      "\n",
      "总记录数: 161034\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 5. 合并数据 ===\n",
    "tweets_with_accounts = pd.merge(\n",
    "    tweets,\n",
    "    accounts,\n",
    "    on=\"author_id\",  # 两边列名相同，直接用 on\n",
    "    how=\"inner\"\n",
    ")\n",
    "print(\"--- 合并后的数据集 ---\")\n",
    "print(tweets_with_accounts.head())\n",
    "print(f\"\\n总记录数: {len(tweets_with_accounts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d0f88ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_accounts.to_csv(\"tweets_with_accounts.csv\", index=False,encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcb16edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posting_date\n",
      "2015-11-30    17947\n",
      "2015-12-01    21812\n",
      "2015-12-02    13264\n",
      "2015-12-03    12090\n",
      "2015-12-04    11288\n",
      "2015-12-05     8139\n",
      "2015-12-06     5276\n",
      "2015-12-07    11661\n",
      "2015-12-08    10673\n",
      "2015-12-09    12109\n",
      "2015-12-10     9164\n",
      "2015-12-11    10962\n",
      "2015-12-12    16649\n",
      "Name: count, dtype: int64\n",
      "推文账户合并信息: 161034\n"
     ]
    }
   ],
   "source": [
    "print(tweets_with_accounts['posting_date'].value_counts().sort_index())\n",
    "total_tweets_accounts = tweets_with_accounts['posting_date'].value_counts().sum()\n",
    "print(f\"推文账户合并信息: {total_tweets_accounts}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
